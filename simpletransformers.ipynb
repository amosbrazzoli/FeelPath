{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python387jvsc74a57bd0fce919f00e395b6eaae18fc4c94b361522f2206a1f6ad63b70b9383a62ddd33b",
   "display_name": "Python 3.8.7 64-bit ('FeelPath': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "fce919f00e395b6eaae18fc4c94b361522f2206a1f6ad63b70b9383a62ddd33b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                text  label\n0  Unfortunately, the frustration of being Dr. Go...      0\n1  Been going to Dr. Goldberg for over 10 years. ...      1\n2  I don't know what Dr. Goldberg was like before...      0\n3  I'm writing this review to give you a heads up...      0\n4  All the food is great here. But the best thing...      1\n                                                text  label\n0  Contrary to other reviews, I have zero complai...      1\n1  Last summer I had an appointment to get new ti...      0\n2  Friendly staff, same starbucks fair you get an...      1\n3  The food is good. Unfortunately the service is...      0\n4  Even when we didn't have a car Filene's Baseme...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "\n",
    "\n",
    "prefix = 'data/yelp_review_polarity_csv/'\n",
    "\n",
    "train_df = pd.read_csv(prefix + 'train.csv', header=None)\n",
    "train_df.head()\n",
    "\n",
    "eval_df = pd.read_csv(prefix + 'test.csv', header=None)\n",
    "eval_df.head()\n",
    "\n",
    "train_df[0] = (train_df[0] == 2).astype(int)\n",
    "eval_df[0] = (eval_df[0] == 2).astype(int)\n",
    "\n",
    "train_df = pd.DataFrame({\n",
    "    'text': train_df[1].replace(r'\\n', ' ', regex=True),\n",
    "    'label':train_df[0]\n",
    "})\n",
    "\n",
    "print(train_df.head())\n",
    "\n",
    "eval_df = pd.DataFrame({\n",
    "    'text': eval_df[1].replace(r'\\n', ' ', regex=True),\n",
    "    'label':eval_df[0]\n",
    "})\n",
    "\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4:14:03,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5262:   1%|          | 380/70000 [01:23<4:12:24,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1060:   1%|          | 380/70000 [01:23<4:12:24,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1060:   1%|          | 381/70000 [01:23<4:11:39,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7460:   1%|          | 381/70000 [01:23<4:11:39,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7460:   1%|          | 382/70000 [01:23<4:10:28,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3297:   1%|          | 382/70000 [01:23<4:10:28,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3297:   1%|          | 383/70000 [01:23<4:09:45,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0266:   1%|          | 383/70000 [01:23<4:09:45,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0266:   1%|          | 384/70000 [01:24<4:08:56,  4.66it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0137:   1%|          | 384/70000 [01:24<4:08:56,  4.66it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0137:   1%|          | 385/70000 [01:24<4:08:39,  4.67it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0079:   1%|          | 385/70000 [01:24<4:08:39,  4.67it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0079:   1%|          | 386/70000 [01:24<4:06:45,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0089:   1%|          | 386/70000 [01:24<4:06:45,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0089:   1%|          | 387/70000 [01:24<4:05:59,  4.72it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2723:   1%|          | 387/70000 [01:24<4:05:59,  4.72it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2723:   1%|          | 388/70000 [01:24<4:06:35,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0088:   1%|          | 388/70000 [01:24<4:06:35,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0088:   1%|          | 389/70000 [01:25<4:05:44,  4.72it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6743:   1%|          | 389/70000 [01:25<4:05:44,  4.72it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6743:   1%|          | 390/70000 [01:25<4:06:40,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6870:   1%|          | 390/70000 [01:25<4:06:40,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6870:   1%|          | 391/70000 [01:25<4:06:12,  4.71it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0156:   1%|          | 391/70000 [01:25<4:06:12,  4.71it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0156:   1%|          | 392/70000 [01:25<4:06:29,  4.71it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5203:   1%|          | 392/70000 [01:25<4:06:29,  4.71it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5203:   1%|          | 393/70000 [01:25<4:06:53,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0663:   1%|          | 393/70000 [01:26<4:06:53,  4.70it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0663:   1%|          | 394/70000 [01:26<4:07:10,  4.69it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0082:   1%|          | 394/70000 [01:26<4:07:10,  4.69it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0082:   1%|          | 395/70000 [01:26<4:08:10,  4.67it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0079:   1%|          | 395/70000 [01:26<4:08:10,  4.67it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0079:   1%|          | 396/70000 [01:26<4:09:05,  4.66it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0080:   1%|          | 396/70000 [01:26<4:09:05,  4.66it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0080:   1%|          | 397/70000 [01:26<4:11:08,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0078:   1%|          | 397/70000 [01:26<4:11:08,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0078:   1%|          | 398/70000 [01:27<4:10:00,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5903:   1%|          | 398/70000 [01:27<4:10:00,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5903:   1%|          | 399/70000 [01:27<4:10:36,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0517:   1%|          | 399/70000 [01:27<4:10:36,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.0517:   1%|          | 400/70000 [01:27<4:09:26,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0216:   1%|          | 400/70000 [01:27<4:09:26,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0216:   1%|          | 401/70000 [01:27<4:13:37,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1756:   1%|          | 401/70000 [01:27<4:13:37,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1756:   1%|          | 402/70000 [01:27<4:17:10,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2857:   1%|          | 402/70000 [01:28<4:17:10,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2857:   1%|          | 403/70000 [01:28<4:16:50,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6324:   1%|          | 403/70000 [01:28<4:16:50,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6324:   1%|          | 404/70000 [01:28<4:15:20,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5036:   1%|          | 404/70000 [01:28<4:15:20,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5036:   1%|          | 405/70000 [01:28<4:14:22,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6086:   1%|          | 405/70000 [01:28<4:14:22,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6086:   1%|          | 406/70000 [01:28<4:14:09,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0221:   1%|          | 406/70000 [01:28<4:14:09,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0221:   1%|          | 407/70000 [01:29<4:14:19,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3421:   1%|          | 407/70000 [01:29<4:14:19,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3421:   1%|          | 408/70000 [01:29<4:11:57,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4701:   1%|          | 408/70000 [01:29<4:11:57,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4701:   1%|          | 409/70000 [01:29<4:12:49,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0272:   1%|          | 409/70000 [01:29<4:12:49,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0272:   1%|          | 410/70000 [01:29<4:13:22,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.9847:   1%|          | 410/70000 [01:29<4:13:22,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.9847:   1%|          | 411/70000 [01:29<4:14:06,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3948:   1%|          | 411/70000 [01:29<4:14:06,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3948:   1%|          | 412/70000 [01:30<4:15:15,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3775:   1%|          | 412/70000 [01:30<4:15:15,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3775:   1%|          | 413/70000 [01:30<4:15:25,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0178:   1%|          | 413/70000 [01:30<4:15:25,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0178:   1%|          | 414/70000 [01:30<4:16:43,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0157:   1%|          | 414/70000 [01:30<4:16:43,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0157:   1%|          | 415/70000 [01:30<4:16:07,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5778:   1%|          | 415/70000 [01:30<4:16:07,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5778:   1%|          | 416/70000 [01:31<4:15:53,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0095:   1%|          | 416/70000 [01:31<4:15:53,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0095:   1%|          | 417/70000 [01:31<4:14:03,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5053:   1%|          | 417/70000 [01:31<4:14:03,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5053:   1%|          | 418/70000 [01:31<4:13:52,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0136:   1%|          | 418/70000 [01:31<4:13:52,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0136:   1%|          | 419/70000 [01:31<4:12:24,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0147:   1%|          | 419/70000 [01:31<4:12:24,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0147:   1%|          | 420/70000 [01:31<4:13:27,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1320:   1%|          | 420/70000 [01:31<4:13:27,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1320:   1%|          | 421/70000 [01:32<4:13:48,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6300:   1%|          | 421/70000 [01:32<4:13:48,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6300:   1%|          | 422/70000 [01:32<4:12:45,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0115:   1%|          | 422/70000 [01:32<4:12:45,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0115:   1%|          | 423/70000 [01:32<4:11:00,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3410:   1%|          | 423/70000 [01:32<4:11:00,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3410:   1%|          | 424/70000 [01:32<4:11:33,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0251:   1%|          | 424/70000 [01:32<4:11:33,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0251:   1%|          | 425/70000 [01:32<4:12:14,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5075:   1%|          | 425/70000 [01:33<4:12:14,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5075:   1%|          | 426/70000 [01:33<4:13:32,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5177:   1%|          | 426/70000 [01:33<4:13:32,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5177:   1%|          | 427/70000 [01:33<4:14:18,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0083:   1%|          | 427/70000 [01:33<4:14:18,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0083:   1%|          | 428/70000 [01:33<4:13:00,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0086:   1%|          | 428/70000 [01:33<4:13:00,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0086:   1%|          | 429/70000 [01:33<4:12:23,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6072:   1%|          | 429/70000 [01:33<4:12:23,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6072:   1%|          | 430/70000 [01:34<4:13:18,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2509:   1%|          | 430/70000 [01:34<4:13:18,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.2509:   1%|          | 431/70000 [01:34<4:14:40,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6510:   1%|          | 431/70000 [01:34<4:14:40,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6510:   1%|          | 432/70000 [01:34<4:16:02,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3060:   1%|          | 432/70000 [01:34<4:16:02,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3060:   1%|          | 433/70000 [01:34<4:16:15,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0088:   1%|          | 433/70000 [01:34<4:16:15,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0088:   1%|          | 434/70000 [01:34<4:14:16,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.9046:   1%|          | 434/70000 [01:35<4:14:16,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.9046:   1%|          | 435/70000 [01:35<4:14:19,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5298:   1%|          | 435/70000 [01:35<4:14:19,  4.56it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5298:   1%|          | 436/70000 [01:35<4:14:43,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0071:   1%|          | 436/70000 [01:35<4:14:43,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0071:   1%|          | 437/70000 [01:35<4:12:33,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0822:   1%|          | 437/70000 [01:35<4:12:33,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0822:   1%|          | 438/70000 [01:35<4:14:43,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0132:   1%|          | 438/70000 [01:35<4:14:43,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0132:   1%|          | 439/70000 [01:36<4:15:09,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5623:   1%|          | 439/70000 [01:36<4:15:09,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5623:   1%|          | 440/70000 [01:36<4:15:42,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0094:   1%|          | 440/70000 [01:36<4:15:42,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0094:   1%|          | 441/70000 [01:36<4:13:29,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.2885:   1%|          | 441/70000 [01:36<4:13:29,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.2885:   1%|          | 442/70000 [01:36<4:12:55,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0609:   1%|          | 442/70000 [01:36<4:12:55,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0609:   1%|          | 443/70000 [01:36<4:13:08,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0202:   1%|          | 443/70000 [01:36<4:13:08,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0202:   1%|          | 444/70000 [01:37<4:12:30,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6206:   1%|          | 444/70000 [01:37<4:12:30,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6206:   1%|          | 445/70000 [01:37<4:12:27,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4785:   1%|          | 445/70000 [01:37<4:12:27,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4785:   1%|          | 446/70000 [01:37<4:11:25,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0135:   1%|          | 446/70000 [01:37<4:11:25,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0135:   1%|          | 447/70000 [01:37<4:10:20,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5205:   1%|          | 447/70000 [01:37<4:10:20,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5205:   1%|          | 448/70000 [01:38<4:09:26,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0284:   1%|          | 448/70000 [01:38<4:09:26,  4.65it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0284:   1%|          | 449/70000 [01:38<4:12:03,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5562:   1%|          | 449/70000 [01:38<4:12:03,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5562:   1%|          | 450/70000 [01:38<4:10:57,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3983:   1%|          | 450/70000 [01:38<4:10:57,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3983:   1%|          | 451/70000 [01:38<4:11:17,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1326:   1%|          | 451/70000 [01:38<4:11:17,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1326:   1%|          | 452/70000 [01:38<4:11:41,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6107:   1%|          | 452/70000 [01:38<4:11:41,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6107:   1%|          | 453/70000 [01:39<4:11:56,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0636:   1%|          | 453/70000 [01:39<4:11:56,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0636:   1%|          | 454/70000 [01:39<4:12:35,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8550:   1%|          | 454/70000 [01:39<4:12:35,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8550:   1%|          | 455/70000 [01:39<4:13:37,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1003:   1%|          | 455/70000 [01:39<4:13:37,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.1003:   1%|          | 456/70000 [01:39<4:14:38,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0159:   1%|          | 456/70000 [01:39<4:14:38,  4.55it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0159:   1%|          | 457/70000 [01:39<4:16:17,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8985:   1%|          | 457/70000 [01:40<4:16:17,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8985:   1%|          | 458/70000 [01:40<4:16:08,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0098:   1%|          | 458/70000 [01:40<4:16:08,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0098:   1%|          | 459/70000 [01:40<4:15:19,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5609:   1%|          | 459/70000 [01:40<4:15:19,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5609:   1%|          | 460/70000 [01:40<4:16:48,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0193:   1%|          | 460/70000 [01:40<4:16:48,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0193:   1%|          | 461/70000 [01:40<4:17:57,  4.49it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0178:   1%|          | 461/70000 [01:40<4:17:57,  4.49it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0178:   1%|          | 462/70000 [01:41<4:17:29,  4.50it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0145:   1%|          | 462/70000 [01:41<4:17:29,  4.50it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0145:   1%|          | 463/70000 [01:41<4:15:00,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1892:   1%|          | 463/70000 [01:41<4:15:00,  4.54it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1892:   1%|          | 464/70000 [01:41<4:17:02,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3896:   1%|          | 464/70000 [01:41<4:17:02,  4.51it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.3896:   1%|          | 465/70000 [01:41<4:17:30,  4.50it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0099:   1%|          | 465/70000 [01:41<4:17:30,  4.50it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0099:   1%|          | 466/70000 [01:41<4:16:07,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4423:   1%|          | 466/70000 [01:42<4:16:07,  4.52it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4423:   1%|          | 467/70000 [01:42<4:15:34,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0104:   1%|          | 467/70000 [01:42<4:15:34,  4.53it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0104:   1%|          | 468/70000 [01:42<4:12:58,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8488:   1%|          | 468/70000 [01:42<4:12:58,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8488:   1%|          | 469/70000 [01:42<4:13:43,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0134:   1%|          | 469/70000 [01:42<4:13:43,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0134:   1%|          | 470/70000 [01:42<4:13:10,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7882:   1%|          | 470/70000 [01:42<4:13:10,  4.58it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.7882:   1%|          | 471/70000 [01:43<4:13:36,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0087:   1%|          | 471/70000 [01:43<4:13:36,  4.57it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0087:   1%|          | 472/70000 [01:43<4:11:08,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0276:   1%|          | 472/70000 [01:43<4:11:08,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0276:   1%|          | 473/70000 [01:43<4:12:11,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0100:   1%|          | 473/70000 [01:43<4:12:11,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0100:   1%|          | 474/70000 [01:43<4:12:42,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8843:   1%|          | 474/70000 [01:43<4:12:42,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8843:   1%|          | 475/70000 [01:43<4:12:26,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4970:   1%|          | 475/70000 [01:43<4:12:26,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.4970:   1%|          | 476/70000 [01:44<4:12:12,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0098:   1%|          | 476/70000 [01:44<4:12:12,  4.59it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0098:   1%|          | 477/70000 [01:44<4:10:29,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6605:   1%|          | 477/70000 [01:44<4:10:29,  4.63it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6605:   1%|          | 478/70000 [01:44<4:11:03,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0077:   1%|          | 478/70000 [01:44<4:11:03,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0077:   1%|          | 479/70000 [01:44<4:10:49,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5624:   1%|          | 479/70000 [01:44<4:10:49,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.5624:   1%|          | 480/70000 [01:45<4:11:50,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0070:   1%|          | 480/70000 [01:45<4:11:50,  4.60it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0070:   1%|          | 481/70000 [01:45<4:09:55,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1535:   1%|          | 481/70000 [01:45<4:09:55,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    1.1535:   1%|          | 482/70000 [01:45<4:10:39,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0068:   1%|          | 482/70000 [01:45<4:10:39,  4.62it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0068:   1%|          | 483/70000 [01:45<4:09:48,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0063:   1%|          | 483/70000 [01:45<4:09:48,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.0063:   1%|          | 484/70000 [01:45<4:09:36,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8388:   1%|          | 484/70000 [01:45<4:09:36,  4.64it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.8388:   1%|          | 485/70000 [01:46<4:11:09,  4.61it/s]\u001b[A\n",
      "Epochs 0/1. Running Loss:    0.6847:   1%|          | 485/70000 [01:46<4:13:52,  4.56it/s]\n",
      "Epoch 1 of 1:   0%|          | 0/1 [01:46<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d5515f2eb90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, train_df, multi_label, output_dir, show_running_loss, args, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         global_step, training_details = self.train(\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataloader, output_dir, multi_label, show_running_loss, eval_df, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m                         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/FeelPath-wtWy25uN/lib/python3.8/site-packages/transformers/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;31m# Just adding the square of the weights to the loss function is *not*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "\n",
    "# Create a TransformerModel\n",
    "model = ClassificationModel('roberta', 'roberta-base')\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}